#version 460 core
#extension GL_GOOGLE_include_directive : enable

#ifdef NVIDIA_PLATFORM
#define WORK_SIZE_BND 1024
#else 
#define WORK_SIZE_BND 1024
#endif

#define BVH_BUILD
#define BVH_CREATION

#include "../include/driver.glsl"
#include "../include/structs.glsl"
#include "../include/uniforms.glsl"
#include "../include/mathlib.glsl"
#include "../include/ballotlib.glsl"
#include "../include/vertex.glsl"
#include "./includes.glsl"




int cdelta( in int a, in int b ){
#if defined(INTEL_PLATFORM)
    uvec2 acode = Mortoncodes[a], bcode = Mortoncodes[b];
    acode.x = a, bcode.x = b;
    return nlz(acode^bcode);
#else 
    uvec2 acode = Mortoncodes[a], bcode = Mortoncodes[b];
    int pfx = nlz(acode^bcode);
    return pfx + (pfx < 64 ? 0 : nlz(a^b));
#endif
}

int findSplit( in int first, in int last) {
    int commonPrefix = cdelta(first, last), split = first, nstep = last - first;
    IFALL (commonPrefix >= 64 || nstep <= 1) { split = (split + last)>>1; } else // if morton code equals
    { //fast search SAH split
        [[dependency_infinite, dependency_length(4)]]
        do {
            int newSplit = split + (nstep = (nstep + 1) >> 1), code = cdelta(split, newSplit);
            split = code > commonPrefix ? newSplit : split;
        } while (nstep > 1);
    }
    return clamp(split, first, last-1);
}


// shared memory counters
shared int _counters[8];
#define cBuffer _counters[3]

// define function for increment
initAtomicSubgroupIncFunction(_counters[0], aCounterInc, 1, int)
initAtomicSubgroupIncFunction(_counters[1], lCounterInc, 2, int)
initAtomicSubgroupIncFunction(_counters[2], cCounterInc, 1, int)
initAtomicSubgroupIncFunction(_counters[2], cCounterDualInc, 2, int)


void splitNode(in int fID, in int side) {
    // select elements, include sibling
    int prID = fID + side;

    [[flatten]]
    if (prID >= 0 && fID >= 0) {
        // initial box and refit status
        bvhBoxesWork[prID] = vec4[2](100000.f.xxxx, -100000.f.xxxx); // initial AABB
        Flags[prID] = 0; // reset flag of refit

        // splitting nodes
        ivec4 _pdata = bvhMeta[prID]-1;

        [[flatten]]
        if (_pdata.x >= 0 && _pdata.y >= 0) {

            [[flatten]]
            if (_pdata.y != _pdata.x) {

                // find split
                int split = findSplit(_pdata.x, _pdata.y);
                ivec4 transplit = ivec4(_pdata.x, split+0, split+1, _pdata.y);
                bvec2 isLeaf = lessThan(transplit.yw - transplit.xz, ivec2(1,1));
                
                // resolve branch
                int hd = lCounterInc();
                bvhMeta[prID] = ivec4(hd.xx+ivec2(0,1)+(1).xx, _pdata.zw+1);
                bvhMeta[hd+0] = ivec4(transplit.xy, prID, -1)+1;
                bvhMeta[hd+1] = ivec4(transplit.zw, prID, -1)+1;

                // add prefix to next task
                Actives[aCounterInc()][cBuffer] = hd+1;
            } 

            // if leaf, add to leaf list
            [[flatten]]
            if (_pdata.y == _pdata.x) {
                LeafIndices[cCounterInc()] = prID+1;
            }
        }
    }
}


layout ( local_size_x = WORK_SIZE_BND ) in;

void main() {
    const int threadID = int(Local_Idx);
    const int groupSize = int(gl_WorkGroupSize.x);

    // lane-based
    const int gS = groupSize >> 1;
    const int iT = threadID >> 1;
    const int sD = threadID & 1;

    ///const int gS = groupSize;
    //const int iT = threadID;
    //const int sD = 0;

    LGROUP_BARRIER
    if (threadID < 8) { _counters[threadID] = 0; }
    LGROUP_BARRIER

    // create initial (root) node
    if (threadID == 0) {
        int hid = lCounterInc();
        bvhMeta[hid+0] = ivec4(1, bvhBlock.creatorUniform.leafCount, 0, 0);
        bvhMeta[hid+1] = ivec4(0, 0, 0, 0);
        Actives[aCounterInc()][cBuffer] = hid+1;
    }
    LGROUP_BARRIER
    
    // building BVH
    [[unroll, dependency_length(4)]]
    for (int m=0;m<65536;m++) {
        // check activity counter
        const int asize = _counters[0];
        IFALL (asize <= 0) break; // if there is no element, stop splitting

        // switch buffer and reset counter
        LGROUP_BARRIER
        if (threadID == 0) { cBuffer = 1-cBuffer; _counters[0] = 0; }
        LGROUP_BARRIER

        // split nodes
        for (int fT=0;fT<asize;fT+=gS) {
            // subgroup barrier
            SB_BARRIER

            // index of node element
            const int uID = fT + iT; 
            
            // split prefixed elements
            IFALL (uID >= asize) break;

            // get spared prefix
            const int fID = Actives[uID][1-cBuffer]-1;
            if (sD == 0) Actives[uID][1-cBuffer] = 0;

            // split sibling nodes
            [[flatten]]
            //if (uID < asize && fID >= 0) { splitNode(fID, 0), splitNode(fID, 1); }
            if (uID < asize && fID >= 0) { splitNode(fID, sD); }
        }

        // sync BVH splitting
        LGROUP_BARRIER
    }

    // copy to external counters
    if (threadID == 0) {
        aCounter = _counters[0];
        lCounter = _counters[1];
        cCounter = _counters[2];
    }
    LGROUP_BARRIER
}
